/*
* Copyright (C) 2024, 2024 Oracle and/or its affiliates.
*
* Licensed under the Universal Permissive License v 1.0 as shown at
* https://oss.oracle.com/licenses/upl/
*/

/*
 * The NoSQLTokenMaker.flex file is inspired from the SQLTokenMaker.flex file, available open-source.
 * The original SQLTokenMaker.flex can be found at:
 * https://github.com/bobbylight/RSyntaxTextArea/blob/master/RSyntaxTextArea/src/main/java/org/fife/ui/rsyntaxtextarea/modes/SQLTokenMaker.flex
 *
 * The NoSQLTokenMaker.java file is generated from NoSQLTokenMaker.flex
 * using the jflex tool, version 1.4.0.
 *
 * Please refer this documentation to know more:
 * https://github.com/bobbylight/RSyntaxTextArea/wiki/Adding-Syntax-Highlighting-for-a-new-Language
 */

package oracle.nosql.intellij.plugin.recordView;

import java.io.IOException;
import java.io.Reader;
import javax.swing.text.Segment;

import org.fife.ui.rsyntaxtextarea.*;


/**
 * This class generates tokens representing a text stream as SQL.<p>
 *
 * This implementation was created using
 * <a href="https://www.jflex.de/">JFlex</a> 1.4.1; however, the generated file
 * was modified for performance.  Memory allocation needs to be almost
 * completely removed to be competitive with the handwritten lexers (subclasses
 * of <code>AbstractTokenMaker</code>), so this class has been modified so that
 * Strings are never allocated (via yytext()), and the scanner never has to
 * worry about refilling its buffer (needlessly copying chars around).
 * We can achieve this because RText always scans exactly 1 line of tokens at a
 * time, and hands the scanner this line as an array of characters (a Segment
 * really).  Since tokens contain pointers to char arrays instead of Strings
 * holding their contents, there is no need for allocating new memory for
 * Strings.<p>
 *
 * The actual algorithm generated for scanning has, of course, not been
 * modified.<p>
 *
 * If you wish to regenerate this file yourself, keep in mind the following:
 * <ul>
 *   <li>The generated <code>NoSQLTokenMaker.java</code> file will contain two
 *       definitions of both <code>zzRefill</code> and <code>yyreset</code>.
 *       You should hand-delete the second of each definition (the ones
 *       generated by the lexer), as these generated methods modify the input
 *       buffer, which we'll never have to do.</li>
 *   <li>You should also change the declaration/definition of zzBuffer to NOT
 *       be initialized.  This is a needless memory allocation for us since we
 *       will be pointing the array somewhere else anyway.</li>
 *   <li>You should NOT call <code>yylex()</code> on the generated scanner
 *       directly; rather, you should use <code>getTokenList</code> as you would
 *       with any other <code>TokenMaker</code> instance.</li>
 * </ul>
 *
 *
 */
%%

%public
%class NoSQLTokenMaker
%extends AbstractJFlexTokenMaker
%unicode
%ignorecase
%type org.fife.ui.rsyntaxtextarea.Token


%{


	/**
	 * Constructor.  This must be here because JFlex does not generate a
	 * no-parameter constructor.
	 */
	public NoSQLTokenMaker() {
		super();
	}


	/**
	 * Adds the token specified to the current linked list of tokens.
	 *
	 * @param tokenType The token's type.
	 */
	private void addToken(int tokenType) {
		addToken(zzStartRead, zzMarkedPos-1, tokenType);
	}


	/**
	 * Adds the token specified to the current linked list of tokens.
	 *
	 * @param tokenType The token's type.
	 */
	private void addToken(int start, int end, int tokenType) {
		int so = start + offsetShift;
		addToken(zzBuffer, start,end, tokenType, so);
	}


	/**
	 * Adds the token specified to the current linked list of tokens.
	 *
	 * @param array The character array.
	 * @param start The starting offset in the array.
	 * @param end The ending offset in the array.
	 * @param tokenType The token's type.
	 * @param startOffset The offset in the document at which this token
	 *                    occurs.
	 */
	@Override
	public void addToken(char[] array, int start, int end, int tokenType, int startOffset) {
		super.addToken(array, start,end, tokenType, startOffset);
		zzStartRead = zzMarkedPos;
	}


	/**
	 * Overridden to return <code>true</code> so paren matching occurs for
	 * SQL.
	 *
	 * @return <code>true</code> always.
	 */
	@Override
	public boolean getCurlyBracesDenoteCodeBlocks(int languageIndex) {
		return true;
	}


	@Override
	public String[] getLineCommentStartAndEnd(int languageIndex) {
		return new String[] { "--", null };
	}


	@Override
	public Token getTokenList(Segment text, int initialTokenType, int startOffset) {

		resetTokenList();
		this.offsetShift = -text.offset + startOffset;

		// Start off in the proper state.
		int state = YYINITIAL;
		switch (initialTokenType) {
			case Token.LITERAL_STRING_DOUBLE_QUOTE:
				state = STRING;
				start = text.offset;
				break;
			case Token.LITERAL_CHAR:
				state = CHAR;
				start = text.offset;
				break;
			case Token.COMMENT_MULTILINE:
				state = MLC;
				start = text.offset;
				break;
			default:
				state = YYINITIAL;
		}

		s = text;
		try {
			yyreset(zzReader);
			yybegin(state);
			return yylex();
		} catch (IOException ioe) {
			ioe.printStackTrace();
			return new TokenImpl();
		}

	}


	/**
	 * Refills the input buffer.
	 *
	 * @return      <code>true</code> if EOF was reached, otherwise
	 *              <code>false</code>.
	 */
	private boolean zzRefill() {
		return zzCurrentPos>=s.offset+s.count;
	}


	/**
	 * Resets the scanner to read from a new input stream.
	 * Does not close the old reader.
	 *
	 * All internal variables are reset, the old input stream
	 * <b>cannot</b> be reused (internal buffer is discarded and lost).
	 * Lexical state is set to <tt>YY_INITIAL</tt>.
	 *
	 * @param reader   the new input stream
	 */
	public final void yyreset(Reader reader) {
		// 's' has been updated.
		zzBuffer = s.array;
		/*
		 * We replaced the line below with the two below it because zzRefill
		 * no longer "refills" the buffer (since the way we do it, it's always
		 * "full" the first time through, since it points to the segment's
		 * array).  So, we assign zzEndRead here.
		 */
		//zzStartRead = zzEndRead = s.offset;
		zzStartRead = s.offset;
		zzEndRead = zzStartRead + s.count - 1;
		zzCurrentPos = zzMarkedPos = zzPushbackPos = s.offset;
		zzLexicalState = YYINITIAL;
		zzReader = reader;
		zzAtBOL  = true;
		zzAtEOF  = false;
	}


%}

LineTerminator		= ([\n])
Letter			= ([A-Za-z])
Digit			= ([0-9])
Whitespace		= ([ \t]+)

IdentifierStart	= ({Letter})
IdentifierPart		= ({IdentifierStart}|{Digit}|[_])
Identifier		= ({IdentifierStart}{IdentifierPart}*)

Operator			= (">="|"<="|"<>"|">"|"<"|"="|"+"|"-"|"*"|"/")
Separator			= ([\(\)])

Parameter			= ([:]{Identifier})

Integer			= ({Digit}+)
Float			= (({Digit}+[.]{Digit}*)|([.]{Digit}*))
ApproxNum			= (({Digit}+[eE][+-]?{Digit}+)|({Digit}+[.]{Digit}*[eE][+-]?[0-9]+)|([.][0-9]*[eE][+-]?[0-9]+))

CommentBegin		= ("--")
Comment			= ({CommentBegin}.*)
MLCBegin			= "/*"
MLCEnd			= "*/"

%state STRING
%state CHAR
%state MLC

%%

<YYINITIAL> {

	/* Keywords */
	"ACCOUNT"|
    "ADD"|
    "ADMIN"|
    "ALL"|
    "ALTER"|
    "ALWAYS"|
    "ANCESTORS"|
    "AND"|
    "AS"|
    "ASC"|
    "ARRAY_COLLECT"|
    "BETWEEN"|
    "BY"|
    "CACHE"|
    "CASE"|
    "CASCADE"|
    "CAST"|
    "COLLECTION"|
    "COMMENT"|
    "COUNT"|
    "CREATE"|
    "CYCLE"|
    "DAYS"|
    "DECLARE"|
    "DEFAULT"|
    "DELETE"|
    "DESC"|
    "DESCENDANTS"|
    "DESCRIBE"|
    "DISTINCT"|
    "DROP"|
    "ELEMENTOF"|
    "ELSE"|
    "END"|
    "ES_SHARDS"|
    "ES_REPLICAS"|
    "EXISTS"|
    "EXTRACT"|
    "FIRST"|
    "FORCE_INDEX"|
    "FORCE_PRIMARY_INDEX"|
    "FREEZE"|
    "FROM"|
    "FROZEN"|
    "FULLTEXT"|
    "GENERATED"|
    "GRANT"|
    "GROUP"|
    "HOURS"|
    "IDENTIFIED"|
    "IDENTITY"|
    "IF"|
    "IN"|
    "INCREMENT"|
    "INDEX"|
    "INDEXES"|
    "INSERT"|
    "INTO"|
    "IS"|
    "JSON"|
    "JOIN"|
    "KEY"|
    "KEYOF"|
    "KEYS"|
    "LAST"|
    "LEFT"|
    "LIFETIME"|
    "LIMIT"|
    "LOCAL"|
    "LOCK"|
    "MAXVALUE"|
    "MINUTES"|
    "MINVALUE"|
    "MODIFY"|
    "MR_COUNTER"|
    "NAMESPACE"|
    "NAMESPACES"|
    "NESTED"|
    "NO"|
    "NOT"|
    "NULLS"|
    "OFFSET"|
    "OF"|
    "ON"|
    "ONLY"|
    "OR"|
    "ORDER"|
    "OUTER"|
    "OVERRIDE"|
    "PASSWORD"|
    "PER"|
    "PREFER_INDEXES"|
    "PREFER_PRIMARY_INDEX"|
    "PRIMARY"|
    "PUT"|
    "REGION"|
    "REGIONS"|
    "REMOVE"|
    "RETURNING"|
    "REVOKE"|
    "ROLE"|
    "ROLES"|
    "ROW"|
    "SCHEMA"|
    "SECONDS"|
    "SELECT"|
    "SEQ_TRANSFORM"|
    "SET"|
    "SHARD"|
    "SHOW"|
    "START"|
    "TABLE"|
    "TABLES"|
    "THEN"|
    "TO"|
    "TTL"|
    "TYPE"|
    "UNFREEZE"|
    "UNLOCK"|
    "UPDATE"|
    "UPSERT"|
    "USER"|
    "USERS"|
    "USING"|
    "VALUES"|
    "WHEN"|
    "WHERE"|
    "WITH"|
    "UNIQUE"|
    "UNNEST"|
    "UUID"  			{ addToken(Token.RESERVED_WORD); }

	"COUNT" 			{ addToken(Token.FUNCTION); }

    "seq_concat" |
    "seq_count" |
    "seq_sum" |
    "seq_avg" |
    "seq_max" |
    "seq_min" |
    "size" |
    "regex_like" |
    "year" |
    "month" |
    "day" |
    "hour" |
    "minute" |
    "second" |
    "millisecond" |
    "microsecond" |
    "nanosecond" |
    "week" |
    "isoweek" |
    "partition" |
    "shard" |
    "row_storage_size" |
    "index_storage_size" |
    "modification_time" |
    "remaining_hours" |
    "remaining_days" |
    "expiration_time" |
    "expiration_time_millis" |
    "geo_intersect" |
    "geo_inside" |
    "geo_within_distance" |
    "geo_near" |
    "geo_distance" |
    "geo_is_geometry" |
    "current_time_millis" |
    "current_time"			{ addToken(Token.FUNCTION); }


	{LineTerminator}				{ addNullToken(); return firstToken; }

	{Identifier}					{ addToken(Token.IDENTIFIER); }
	";"							{ addToken(Token.IDENTIFIER); }

	{Parameter}					{ addToken(Token.IDENTIFIER); }

	{Comment}						{ addToken(Token.COMMENT_EOL); }
	{MLCBegin}					{ start = zzMarkedPos-2; yybegin(MLC); }

	{Whitespace}					{ addToken(Token.WHITESPACE); }

	{Operator}					{ addToken(Token.OPERATOR); }
	{Separator}					{ addToken(Token.SEPARATOR); }

	{Integer}						{ addToken(Token.LITERAL_NUMBER_DECIMAL_INT); }
	{Float}						{ addToken(Token.LITERAL_NUMBER_FLOAT); }
	{ApproxNum}					{ addToken(Token.LITERAL_NUMBER_FLOAT); }

	"\""							{ start = zzMarkedPos-1; yybegin(STRING); }
	"\'"							{ start = zzMarkedPos-1; yybegin(CHAR); }

    // MS-SQL square bracket identifiers
	"["[^\]]*"]"					{ addToken(Token.PREPROCESSOR); }
	"["[^\]]*						{ addToken(Token.ERROR_IDENTIFIER); addNullToken(); return firstToken; }

	<<EOF>>						{ addNullToken(); return firstToken; }

	/* Catch any other (unhandled) characters and flag them as OK; */
	/* I don't know enough about SQL to know what's really invalid. */
	.							{ addToken(Token.IDENTIFIER); }

}

<STRING> {

	[^\n\"]+				{}
	\n					{ addToken(start,zzStartRead-1, Token.LITERAL_STRING_DOUBLE_QUOTE); return firstToken; }
	"\"\""				{}
	"\""					{ yybegin(YYINITIAL); addToken(start,zzStartRead, Token.LITERAL_STRING_DOUBLE_QUOTE); }
	<<EOF>>				{ addToken(start,zzStartRead-1, Token.LITERAL_STRING_DOUBLE_QUOTE); return firstToken; }

}

<CHAR> {

	[^\n\']+				{}
	\n					{ addToken(start,zzStartRead-1, Token.LITERAL_CHAR); return firstToken; }
	"\'\'"				{}
	"\'"					{ yybegin(YYINITIAL); addToken(start,zzStartRead, Token.LITERAL_CHAR); }
	<<EOF>>				{ addToken(start,zzStartRead-1, Token.LITERAL_CHAR); return firstToken; }

}

<MLC> {

	[^\n\*]+				{}
	\n					{ addToken(start,zzStartRead-1, Token.COMMENT_MULTILINE); return firstToken; }
	{MLCEnd}				{ yybegin(YYINITIAL); addToken(start,zzStartRead+1, Token.COMMENT_MULTILINE); }
	\*					{}
	<<EOF>>				{ addToken(start,zzStartRead-1, Token.COMMENT_MULTILINE); return firstToken; }

}